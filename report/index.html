<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8" />
<meta name="generator" content="quarto-1.6.43" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />

<meta name="author" content="Dhruv Dole" />
<meta name="author" content="Nathan Rethwisch" />
<meta name="author" content="Colin Russell" />
<meta name="author" content="Thanh Mai" />
<meta name="description" content="DS 4010 - Wildfire Dashboard" />

<title>Final Report</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<!-- htmldependencies:E3FAD763 -->
<script async src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>


<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-full">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <div id="quarto-toc-target"></div>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Final Report</h1>
</div>

<div>
  <div class="description">
    DS 4010 - Wildfire Dashboard
  </div>
</div>

<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Dhruv Dole </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Iowa State University
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Nathan Rethwisch </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Iowa State University
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Colin Russell </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Iowa State University
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Thanh Mai </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Iowa State University
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  


</header>

<nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introductionproject-description" id="toc-introductionproject-description">Introduction/Project Description</a></li>
  <li><a href="#data" id="toc-data">Data</a>
  <ul>
  <li><a href="#sources-acquisition" id="toc-sources-acquisition">Sources &amp; Acquisition</a></li>
  <li><a href="#transformations" id="toc-transformations">Transformations</a></li>
  <li><a href="#storage-and-query-engine" id="toc-storage-and-query-engine">Storage and Query Engine</a></li>
  </ul></li>
  <li><a href="#exploration-and-analysis" id="toc-exploration-and-analysis">Exploration and Analysis</a></li>
  <li><a href="#modeling" id="toc-modeling">Modeling</a>
  <ul>
  <li><a href="#data-preparation" id="toc-data-preparation">Data Preparation</a></li>
  <li><a href="#model-selection" id="toc-model-selection">Model Selection</a></li>
  <li><a href="#hyperparameter-selection" id="toc-hyperparameter-selection">Hyperparameter Selection</a></li>
  <li><a href="#results" id="toc-results">Results</a></li>
  <li><a href="#challenges" id="toc-challenges">Challenges</a></li>
  </ul></li>
  <li><a href="#dashboard" id="toc-dashboard">Dashboard</a>
  <ul>
  <li><a href="#exploration" id="toc-exploration">Exploration</a></li>
  <li><a href="#dashboard-creation" id="toc-dashboard-creation">Dashboard Creation</a></li>
  <li><a href="#interface" id="toc-interface">Interface</a></li>
  <li><a href="#challenges-1" id="toc-challenges-1">Challenges</a></li>
  <li><a href="#availabilitysource-code-location" id="toc-availabilitysource-code-location">Availability/Source Code Location</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion">Conclusion</a>
  <ul>
  <li><a href="#summary" id="toc-summary">Summary</a></li>
  <li><a href="#further-discussion" id="toc-further-discussion">Further Discussion</a></li>
  <li><a href="#sources" id="toc-sources">Sources</a></li>
  </ul></li>
  </ul>
</nav>
<section id="introductionproject-description" class="level2">
<h2>Introduction/Project Description</h2>
<p>Wildfires are a major problem in the United States, costing between $394 billion and $893 billion per year, according to the Joint Economic Committee <span class="citation" data-cites="jec2023wildfires">(<a href="#ref-jec2023wildfires" role="doc-biblioref">U.S. Congress Joint Economic Committee 2023</a>)</span>. Identifying where and why wildfires occur is key to preventing wildfires, which protects lives, preserves property, and minimizes economic losses. The goal of this project is to estimate areas of high fire risk based on historical weather patterns and wildfire data. We aim to provide a platform where users can obtain information about past weather conditions and their association with wildfires at a quick glance. This dashboard is designed for a broad audience, including high-level policymakers involved in wildfire prevention strategies and local officials responsible for establishing rules and regulations based on regional wildfire risk.</p>
<div id="fig-WildfireCost" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-WildfireCost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="WildfireCost.png" class="img-fluid" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-WildfireCost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 1: Estimated Cost of Wildfires in 2022
</figcaption>
</figure>
</div>
</section>
<section id="data" class="level2">
<h2>Data</h2>
<section id="sources-acquisition" class="level3">
<h3>Sources &amp; Acquisition</h3>
<section id="global-historical-climatology-network-daily-ghcnd" class="level4">
<h4>Global Historical Climatology Network daily (GHCND)</h4>
<p>The Global Historical Climatology Network daily (GHCND) is an integrated database of daily climate summaries from land surface stations worldwide. It includes records from over 100,000 stations in 180 countries, providing data on variables such as temperature, precipitation, snowfall, and snow depth. This data is provided in its raw form by the National Oceanic and Atmospheric Administration <a href="https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily">here</a>. The same data is available in different formats published as an AWS Open Data <a href="https://registry.opendata.aws/noaa-ghcn/">dataset</a>. The latter dataset was selected because it provides data as comma-separated-values instead of fixed-width tables.</p>
<p>There are two raw ‘tables’ available from the dataset: <code>stations</code> and <code>daily</code>. <code>stations</code> is available as a single fixed-width text file, and provides a mapping of weather station IDs and geographic coordinates. <code>daily</code> is made up of csv records, where each record corresponds to a single observation made by a station. The data is partitioned by year, with a single compressed csv for each year. Source data exists for the year range of <span class="math inline">\(1776\)</span> to <span class="math inline">\(2025\)</span>, however before the year <span class="math inline">\(2000\)</span> there is a comparatively small amount of data. It was decided to focus on data from <span class="math inline">\(2000\)</span> onwards.</p>
<p>In order to create cleaned tables, it was necessary first to mirror the raw data locally to avoid the need for repeated downloads of the same files. A python script was written which parses the s3 bucket <a href="https://noaa-ghcn-pds.s3.amazonaws.com/">manifest</a> and downloads all <code>daily</code> files with the <code>csv.gz</code> suffix for years after <span class="math inline">\(1999\)</span>. The script also downloads a copy of the file <code>stations.txt</code>, the raw source for <code>stations</code>.</p>
<section id="first-5-lines-of-daily-file-2010.csv.gz" class="level5">
<h5>First 5 lines of daily file 2010.csv.gz</h5>
<pre><code>AE000041196,20100101,TMAX,259,,,S,
AE000041196,20100101,TMIN,120,,,S,
AE000041196,20100101,TAVG,181,H,,S,
AEM00041194,20100101,TMAX,250,,,S,
AEM00041194,20100101,TMIN,168,,,S,</code></pre>
</section>
<section id="first-5-lines-of-stations.txt" class="level5">
<h5>First 5 lines of stations.txt</h5>
<pre><code>ACW00011604  17.1167  -61.7833   10.1    ST JOHNS COOLIDGE FLD                       
ACW00011647  17.1333  -61.7833   19.2    ST JOHNS                                    
AE000041196  25.3330   55.5170   34.0    SHARJAH INTER. AIRP            GSN     41196
AEM00041194  25.2550   55.3640   10.4    DUBAI INTL                             41194
AEM00041217  24.4330   54.6510   26.8    ABU DHABI INTL                         41217</code></pre>
</section>
</section>
<section id="national-us-forest-service-fire-occurence-point" class="level4">
<h4>National US Forest Service Fire Occurence Point</h4>
<p>The FireOccurrence point layer represents ignition points, or points of origin, from which individual USFS wildland fires started. Data are maintained at the Forest/District level, or their equivalent, to track the occurrence and the origin of individual USFS wildland fires. It includes variables such as Discovery Date, Total Acres, Stat Cause, LatitudeDD83, LongitudeDD83 and much more. All of the information is publicly avaliable <a href="https://catalog.data.gov/dataset/national-usfs-fire-occurrence-point-feature-layer-d3233">here</a>. There are multiple formats that the data can be downloaded in, but our group used a csv file.</p>
</section>
</section>
<section id="transformations" class="level3">
<h3>Transformations</h3>
<section id="ghcnd" class="level4">
<h4>GHCND</h4>
<p>The transformations for the GHCN Daily data is a single script because the required transformations were changing almost every day, and it was often necessary to rebuild the dataset outright. This also allows for anyone to reproduce the dataset.</p>
<p>The raw daily data includes one column designating the type of observation, and one the actual value recorded. The desired end result was a single table, with a column for each desired observation type or <code>element</code>. Once joined with station locations, the data was indexed using the <a href="https://h3geo.org/">h3</a> library. This has many benefits which are described <a href="#exploration-and-analysis">below</a></p>
<p>The basic steps are as follows: <code>stations.txt</code> needs to be converted from a fixed-width text file to a typed parquet file. Each daily file needs to be decompressed, typed, and reoriented into the correct format.</p>
<p>The transformation steps are shown in this diagram:</p>
<pre class="mermaid"><code>graph TD
    A[stations.txt] --&gt; D
    D[read fwf] --&gt; H

    C[raw daily] --&gt; B[decompress]
    B --&gt; E[process dates]
    E --&gt; F[drop unwanted columns]
    F --&gt; G[create single element tables]
    G --&gt; I[join element tables]
    I --&gt; J[join with stations]
    J --&gt; K[generate point geometries]
    K --&gt; L[index with h3]
    L --&gt; H

    H[save as parquet]

    M[read stations.parquet] --&gt; J</code></pre>
<p>Once the data was in a viewable format, columns to drop were chosen based by generating percentage nulls. Each time it was decided to keep or drop a column, the column was added or removed from a <code>keep_columns</code> list, and the pipeline was re-run. See <a href="#tbl-2010.parquet" class="quarto-xref">Table 1</a> for the resultant table.</p>
<div id="tbl-2010.parquet" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-tbl">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-2010.parquet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table 1: First 5 rows of 2010.parquet
</figcaption>
<div aria-describedby="tbl-2010.parquet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top">
<colgroup>
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">station_id</th>
<th style="text-align: left;">year</th>
<th style="text-align: left;">month</th>
<th style="text-align: left;">day</th>
<th style="text-align: left;">prcp</th>
<th style="text-align: left;">snow</th>
<th style="text-align: left;">snwd</th>
<th style="text-align: left;">tmax</th>
<th style="text-align: left;">tmin</th>
<th style="text-align: left;">awnd</th>
<th style="text-align: left;">awdr</th>
<th style="text-align: left;">evap</th>
<th style="text-align: left;">latitude</th>
<th style="text-align: left;">longitude</th>
<th style="text-align: left;">elevation</th>
<th style="text-align: left;">state</th>
<th style="text-align: left;">geometry</th>
<th style="text-align: left;">Hexagon_ID</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">CA001011500</td>
<td style="text-align: left;">2010</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">245</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">85</td>
<td style="text-align: left;">35</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">48.9333</td>
<td style="text-align: left;">-123.75</td>
<td style="text-align: left;">75</td>
<td style="text-align: left;">BC</td>
<td style="text-align: left;">0x0101000000ACADD85F767748400000000000F05EC0</td>
<td style="text-align: left;">8328dcfffffffff</td>
</tr>
<tr class="even">
<td style="text-align: left;">CA001011500</td>
<td style="text-align: left;">2010</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">100</td>
<td style="text-align: left;">55</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">48.9333</td>
<td style="text-align: left;">-123.75</td>
<td style="text-align: left;">75</td>
<td style="text-align: left;">BC</td>
<td style="text-align: left;">0x0101000000ACADD85F767748400000000000F05EC0</td>
<td style="text-align: left;">8328dcfffffffff</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CA001011500</td>
<td style="text-align: left;">2010</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">78</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">70</td>
<td style="text-align: left;">30</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">48.9333</td>
<td style="text-align: left;">-123.75</td>
<td style="text-align: left;">75</td>
<td style="text-align: left;">BC</td>
<td style="text-align: left;">0x0101000000ACADD85F767748400000000000F05EC0</td>
<td style="text-align: left;">8328dcfffffffff</td>
</tr>
<tr class="even">
<td style="text-align: left;">CA001011500</td>
<td style="text-align: left;">2010</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">205</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">65</td>
<td style="text-align: left;">50</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">48.9333</td>
<td style="text-align: left;">-123.75</td>
<td style="text-align: left;">75</td>
<td style="text-align: left;">BC</td>
<td style="text-align: left;">0x0101000000ACADD85F767748400000000000F05EC0</td>
<td style="text-align: left;">8328dcfffffffff</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CA001011500</td>
<td style="text-align: left;">2010</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">80</td>
<td style="text-align: left;">50</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">null</td>
<td style="text-align: left;">48.9333</td>
<td style="text-align: left;">-123.75</td>
<td style="text-align: left;">75</td>
<td style="text-align: left;">BC</td>
<td style="text-align: left;">0x0101000000ACADD85F767748400000000000F05EC0</td>
<td style="text-align: left;">8328dcfffffffff</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="national-us-forest-service-fire-occurence-point-1" class="level4">
<h4>National US Forest Service Fire Occurence Point</h4>
<p>The transformations to the fire occurence dataset were done using R. The major issue with the dataset was there were a lot of null values, some of the 44 variables were unusable due to the amount of missing data. The variables our group decided to include were <code>UNIQFIREID</code>, <code>FIREYEAR</code>, <code>DISCOVERYDATETIME</code>, <code>FIREOUTDATETIME</code>, <code>SIZECLASS</code>, <code>TOTALACRES</code>, <code>STATCAUSE</code>, <code>LATDD83</code>, and <code>LONGDD83</code>. Most of these variables only had <code>NA</code>/null values that needed to be removed. The hardest part was attempting to clean the Stat Cause column because of the sheer amount of misslabeled causes of fire. After dealing with these issues the dataset was reduced from <span class="math inline">\(580,000\)</span> rows and <span class="math inline">\(35\)</span> variables to <span class="math inline">\(245,000\)</span> rows and <span class="math inline">\(10\)</span> variables. Lastly, the finalized dataset was exported as a parquet file to preserve variable types and remove the need to repedeatly run the cleaning script.</p>
<p>The transformation steps are shown in this diagram:</p>
<pre class="mermaid"><code>  graph TD
    A[Read CSV] --&gt; B[Select relevant columns]
    B --&gt; C[Remove NA values]
    C --&gt; D[Clean FIREYEAR ]
    D --&gt; E[Verify SIZECLASS vs TOTALACRES]
    E --&gt; F[Sample and inspect LAT/LONG]
    F --&gt; G[Clean STATCAUSE]
    G --&gt; H[Export as a parquet file]</code></pre>
<section id="first-5-lines-of-fire-occurence" class="level5">
<h5>First 5 lines of Fire Occurence</h5>
<pre><code>          X        Y  OBJECTID                               GLOBALID                         FIREOCCURID CN                   REVDATE                            
1 -106.4278 39.84611 231055009 {540C6E70-51FD-4CCC-A1B3-8A6C914E34A3}   2B1B9A1B-7828-4688-A14C-4BD7CEE62226    2023/03/29 11:10:56+00
2 -107.9356 39.37278 231055010 {ACE77CF8-1281-4A81-BE3D-4D55669CB134}   A2454D64-EBB7-4895-81BC-9782B3D1391E    2023/03/29 11:10:59+00
3 -106.7233 39.11833 231055011 {D8EA7329-A0D0-4B64-A6F2-7A7FD86A3505}                                           2023/03/29 11:10:56+00
4 -106.5900 39.65667 231055012 {67A72390-0E2B-411E-9CDE-6657101645E4}                                           2023/03/29 11:10:56+00
5 -107.3173 40.01929 231055013 {DFFF8D93-DE89-451C-830C-1F65FD550B3D}   558D5D61-AB04-4AC3-8143-2E0EBE7CB506    2024/03/27 14:21:08+00
6 -106.5183 39.58833 231055014 {B7FC6338-897C-44AC-BD8B-7D1EB63EC7D8}                                           2023/03/29 11:10:56+00

                   FIRENAME COMPLEXNAME FIREYEAR        UNIQFIREID SOFIRENUM  LOCALFIRENUM SECURITYID       DISCOVERYDATETIME SIZECLASS TOTALACRES    STATCAUSE
1             Elliott Ridge                 2016 2016-COWRF-000679       039           679       0215  2016/10/22 00:00:01+00         A       0.25      Camping
2 Battlement Mesa Reservoir                 2016 2016-COWRF-000452       018           452       0215  2016/08/07 00:00:01+00         A       0.10      Camping
3                 Difficult                 1997   1997-COWRF-000        013                     0215  1997/07/26 00:00:01+00         A       0.10    Lightning
4                                           1993   1993-COWRF-000        022                     0215  1993/08/23 00:00:01+00         A       0.10 Undetermined
5                  Paradise                 2020 2020-COWRF-000504                     504       0215  2020/10/14 13:16:01+00         A       0.10      Camping
6                      B.C.                 1994   1994-COWRF-000        039                     0215  1994/07/29 00:00:01+00         A       0.10    Lightning

  COMMENTS DATASOURCE        FIREOUTDATETIME OWNERAGENCY UNITIDOWNER   PROTECTIONAGENCY UNITIDPROTECT  LATDD83  LONGDD83 FIRETYPECATEGORY POINTTYPE
1                  24 2017/02/06 11:54:01+00        USFS       COWRF               USFS         COWRF 39.84611 -106.4278               WF   General
2                  24 2016/08/12 11:20:01+00        USFS       COWRF               USFS         COWRF 39.37278 -107.9356               WF   General
3                  24 1997/07/28 16:57:01+00        USFS       COWRF               USFS         COWRF 39.11833 -106.7233               WF   General
4                  24 1993/08/23 23:00:01+00        USFS       COWRF               USFS         COWRF 39.11833 -106.7233               WF   General
5                  24 2020/11/12 14:30:01+00        USFS       COWRF               USFS         COWRF 39.65667 -106.5900               WF   General
6                  24 1994/07/29 18:00:01+00        USFS       COWRF               USFS         COWRF 39.58833 -106.5183               WF   General

  PERIMEXISTS FIRERPTQC DBSOURCEID           DBSOURCEDATE ACCURACY SHAPE
1           N       Yes        215 2024/09/24 04:01:09+00    24000    NA
2           N       Yes        215 2024/09/24 04:01:15+00    24000    NA
3           N       Yes        215 2024/09/24 04:01:15+00    24000    NA
4           N       Yes        215 2024/09/24 04:01:15+00    24000    NA
5           Y       Yes        215 2024/09/24 04:01:15+00    24000    NA
6           N       Yes        215 2024/09/24 04:01:15+00    24000    NA</code></pre>
</section>
</section>
</section>
<section id="storage-and-query-engine" class="level3">
<h3>Storage and Query Engine</h3>
<p>To handle selections, projections, and group by aggregations on larger-than-memory datasets, <a href="https://arrow.apache.org/docs/python/index.html">PyArrow</a> and Parquet were chosen for their support of lazy evaluation and predicate pushdown, which reduced query time by as much as 700%. These tools also support easy conversion to Pandas dataframes and there is also an <a href="https://arrow.apache.org/docs/r/">Arrow for R</a> package allowing some team members to use R where desired.</p>
<p>The largest operational issue was that the dataset needed to be identical across each developer’s machines. To avoid paying for cloud resources, the data was stored in a shared OneDrive folder and symlinked into the local repository by each user, ensuring uniform access paths while allowing individual developers to manage their data access. This setup allowed each user to download the dataset to their local system on demand, while keeping their copy up-to-date.</p>
<p>Initially, the assumption was that the entire dataset needed to be available to the dashboard, but later it was realized that only the 3-day averages produced as part of the model training were necessary. This allowed the dashboard’s live data to be loaded into memory on initialization. This means that the dashboard does not require high througput IO access.</p>
</section>
</section>
<section id="exploration-and-analysis" class="level2">
<h2>Exploration and Analysis</h2>
<div id="fig-UberH3" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-UberH3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="UberH3.png" class="img-fluid" style="width:50.0%" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-UberH3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 2: An example of Uber’s H3 Cell Grid
</figcaption>
</figure>
</div>
<p>After cleaning the data and performing exploratory data analysis, we realized we needed a way to process data that contained both geospatial and time information. One additional challenge we faced was the lack of negative data. Our dataset contained a list of places where fires occurred, but not where they <em>did not</em> occur. Thus, this makes it difficult to create a binary prediction model of fire probability, because we only have cases where the fires occurred to train models on. To solve these problems, we turned to Uber’s H3 cell grid, shown in <a href="#fig-UberH3" class="quarto-xref">Figure 2</a>. H3 cells are a series of hexagonal cells that can be used to cover the surface of the globe at different resolutions. Although perhaps not as precise as certain geographical boundaries for prediction, H3 hexagons are advantageous because of their computational speed and equidistant between neighboring cells. In our case, we fit a grid of cells to the US, with each hexagon representing approximately 4785 square miles, totaling 712 cells. For each day, we marked whether or not a fire occurred in each hex. Meteorological stations within a cell were aggregated to compute mean calculations for weather data. The additional advantage of these cells was that we no longer needed to spatially join the fire and weather data to perform calculations. Once we had the index of the cell, we knew exactly which stations were paired with which fires, saving us the time and computation of continuous joins.</p>
<p>Another challenge was missing data. If all of the weather stations in a cell gave null values for a variable on a certain date, they were imputed with the average from neighboring cells. We also removed precipitation from our analysis because over 50% of the precipitation data was missing.</p>
</section>
<section id="modeling" class="level2">
<h2>Modeling</h2>
<section id="data-preparation" class="level3">
<h3>Data Preparation</h3>
<p>With the addition of H3 cells and negative data for cells without a fire, we fit a model to predict <span class="math inline">\(Y_ij\)</span>, the probability of a fire occurring in cell <span class="math inline">\(i\)</span> on day <span class="math inline">\(j\)</span>, bounded by <span class="math inline">\([0,1]\)</span>. We averaged the weather variables over three days, the two days before the fire and the day the fire occurred, for our predictors.<br />
Prediction variables were as follows:</p>
<ul>
<li><span class="math inline">\(x_1\)</span>: Hexagon location<br />
</li>
<li><span class="math inline">\(x_2\)</span>: Average Elevation<br />
</li>
<li><span class="math inline">\(x_3\)</span>: Temperature Maximum (3-day average)<br />
</li>
<li><span class="math inline">\(x_4\)</span>: Temperature Minimum (3-day average)<br />
</li>
<li><span class="math inline">\(x_5\)</span>: Daily Average Wind Speed (3-day average)<br />
</li>
<li><span class="math inline">\(x_6\)</span>: Precipitation (3-day average)<br />
</li>
<li><span class="math inline">\(x_7\)</span>: Snowfall (3-day average)<br />
</li>
<li><span class="math inline">\(x_7\)</span>: Month</li>
</ul>
</section>
<section id="model-selection" class="level3">
<h3>Model Selection</h3>
<p>We split the data into a training and a testing set. The training data ranges from January 1, 2000, to December 31, 2019. The testing data was from January 1, 2020, to March 23, 2025. I encoded the hexagonal location as numeric variables and ran 4 separate models: logistic regression, random forest, XGBoost, and Naive Bayes. After running the models, I then simulated thresholds from 0-1 at a 0.01 interval and selected the optimal prediction threshold for each model that maximized the F1 score, which can be defined as <span class="math inline">\(\frac{\text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}}\)</span>.</p>
<ul>
<li>Precision is defined as how often a positive wildfire prediction is correctly positive. It can be defined as <span class="math inline">\(\frac{\text{TP}}{\text{TP} + \text{FP}}\)</span>.<br />
</li>
<li>Recall describes the rate at which the model can correctly identify true positives from all possible values. It can be defined as <span class="math inline">\(\frac{\text{TP}}{\text{TP} + \text{FN}}\)</span>.</li>
</ul>
<p>F1 score is preferential to accuracy in this case, because the dataset is imbalanced and we have very few actual positive cases of wildfires, so models that maximize accuracy are likely to underestimate the probability of a fire occurring, a more costly mistake than a false positive.</p>
<p><a href="#fig-thresholds" class="quarto-xref">Figure 3</a> shows the optimal thresholds curves, while <a href="#fig-modelTable" class="quarto-xref">Figure 4</a> displays statistics for each model in the selection process.</p>
<div id="fig-thresholds" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-thresholds-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="thresholds.png" style="width:50.0%;height:50.0%" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-thresholds-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 3: Thresholds for the optimal F1 score using each model
</figcaption>
</figure>
</div>
<div id="fig-modelTable" class="quarto-float quarto-figure quarto-figure-center" data-fig-cap-location="top">
<figure class="quarto-float quarto-float-fig">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-modelTable-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 4: Statistics for each model fit on historical weather data
</figcaption>
<div aria-describedby="fig-modelTable-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="modelStats.jpg" class="img-fluid" data-fig-cap-location="top" />
</div>
</figure>
</div>
<p>Based on these results, we decided to go with a random forest model. Although the XGBoost and random forest models performed similarly, the random forest model had a higher F1 score as well as higher accuracy. Furthermore, we are more familiar with working with random forests. Given more time, we would explore the XGBoost model, especially since it has higher recall, which is desirable given that the cost of a false negative is high.</p>
</section>
<section id="hyperparameter-selection" class="level3">
<h3>Hyperparameter Selection</h3>
<p>After deciding on a random forest as the optimal model, we performed a grid search with 3-fold cross-validation to fine-tune model parameters. We used a random sample of 10% of the data due to storage limits. The parameters of interest were the number of estimators in the forest (50, 100, 200), the maximum depth of each tree considered (None, 10, 20, 30), and the number of features considered at each split (2, 3). Therefore, 24 possible combinations were considered. Using a decision threshold of 0.22, we selected the model with the highest F1 score. Ultimately, this was selected to be one with 200 estimators, a max depth of 30, and 3 features considered at each split. <a href="#fig-codeRF" class="quarto-xref">Figure 5</a> shows the trained random forest using this</p>
<div id="fig-codeRF" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-codeRF-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="BestRandomForest.png" class="img-fluid" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-codeRF-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 5: Code for Training the Optimal Random Forest
</figcaption>
</figure>
</div>
</section>
<section id="results" class="level3">
<h3>Results</h3>
<p>After fitting the fine-tuned model to the training and testing data, we ended with <a href="#tbl-model-metrics" class="quarto-xref">Table 2</a>. Hyperparameter tuning was able to marginally improve F1 score (0.193 to 0.197) and recall (0.305 to 0.330). Although these scores are still fairly low, this is somewhat expected due to the limit of our data and the variability of fire causes. <a href="#tbl-feature-importance" class="quarto-xref">Table 3</a> shows a table of the most important features, showing that location, elevation, and temperature were seen as key predictors of wildfires.</p>
<!-- ![Statistics for our Random Forest after Hyperpararmeter Tuning](bestModelStats.png){#fig-bestModelStats fig-cap-location="top"}   -->
<div id="tbl-model-metrics" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-tbl">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-model-metrics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table 2: Model metrics for random forest after hyperparameter tuning
</figcaption>
<div aria-describedby="tbl-model-metrics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top">
<thead>
<tr class="header">
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Optimal Threshold</td>
<td>0.21</td>
</tr>
<tr class="even">
<td>Accuracy</td>
<td>0.957575</td>
</tr>
<tr class="odd">
<td>Precision</td>
<td>0.148936</td>
</tr>
<tr class="even">
<td>Recall</td>
<td>0.333333</td>
</tr>
<tr class="odd">
<td>F1 Score</td>
<td>0.197802</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div id="tbl-feature-importance" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-tbl">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-feature-importance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table 3: Feature Importance
</figcaption>
<div aria-describedby="tbl-feature-importance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top">
<thead>
<tr class="header">
<th>Feature</th>
<th>Importance Score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Hexagon Location</td>
<td>0.2056</td>
</tr>
<tr class="even">
<td>Average Elevation</td>
<td>0.1826</td>
</tr>
<tr class="odd">
<td>Temperature Maximum (3-Day Average)</td>
<td>0.1685</td>
</tr>
<tr class="even">
<td>Temperature Minimum (3-Day Average)</td>
<td>0.1611</td>
</tr>
<tr class="odd">
<td>Daily Average Wind (3-Day Average)</td>
<td>0.1345</td>
</tr>
<tr class="even">
<td>Precipitation (3-Day Average)</td>
<td>0.1003</td>
</tr>
<tr class="odd">
<td>Month</td>
<td>0.0414</td>
</tr>
<tr class="even">
<td>Snowfall (3-Day Average)</td>
<td>0.0059</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>After running the model, the output was saved as a parquet file and loaded later into the dashboard.</p>
</section>
<section id="challenges" class="level3">
<h3>Challenges</h3>
<p>One of the key challenges faced when running the model was the large amount of data we faced. Because we are dealing with both time and spatial data, we were dealing with a dataframe that has a row for every unique combination of dates from 2020-2025 and hexagon locations (of which there are 712). This gives a dataset with a total of 188,240,121 rows. This was too large to load into memory on our local devices, so we used the workstations in the The Catalyst, a space in Parks Libary. These are high-performance workstations that are reservable by students at the Iowa State Library. We loaded the data and were able to save the model output through OneDrive.</p>
</section>
</section>
<section id="dashboard" class="level2">
<h2>Dashboard</h2>
<section id="exploration" class="level3">
<h3>Exploration</h3>
<p>We originally explored ArcGIS’s online dashboarding tools due to its seamless integration with geospatial data. However, loading hexagonal maps with predictions for each date proved to be too large a task for the software to handle, leading to incredible slow loading times. As a result, we turned to Python’s Dash library. This was able to handle large amounts of data and gave the option to add map layers easily.</p>
</section>
<section id="dashboard-creation" class="level3">
<h3>Dashboard Creation</h3>
<ul>
<li>Explored arcgis(slow, generally too limited in feature set)<br />
</li>
<li>Chose dash because data was large and required custom real-time querying, needed efficient real-time map generation and rendering<br />
</li>
<li>Stack: mixed python/r, dash, leaflet, containerized with docker, self-hosted<br />
</li>
<li>Key visualization: fire risk probability, climate data<br />
</li>
<li>Precomputed all values and plots needed for dashboard. The only realtime workload is selecting a single day’s render fields.<br />
</li>
<li>many many pictures</li>
</ul>
<p>All of the values for the dashboard were precomputed from the model. For the colors of the map, output was normalized using the following formula:<br />
<span class="math display">\[\frac{x - x_{min}}{x_{max} - x_{min}}\]</span><br />
However, the actual predicted output and color bar on the map reverse this normalization so that the labels match the real predicted and weather values.</p>
</section>
<section id="interface" class="level3">
<h3>Interface</h3>
<p>The dashboard has three main tabs. The map view allows users to set a date to view an overlay of wildfire predictions within hexagons on a map of the United States. The user can select the date displayed using a date slider at the bottom of the page. They can also select different variables in the tab menu on the map to get weather data for that date, allowing users to easily visualize weather patterns and areas of high fire probability. When viewing the map, users can click on a specific hex to get both model output and weather for that area on that selected date. Model output can be copied to clipboard for advanced analytics and reporting.</p>
<p>The time series plot was created in R using Plotly and is hosted as a HTML file. The plot shows 2 lines the red line depicts the fires occured per week and the green line depcits the average acres burned that week. There buttons in the top left corner that allow users to view in 6 month or year long increments</p>
<p>Finally, the dashboard info tab gives information about the underlying model and how to use the dashboard. It was created in R using Quarto and is also implemented as an HTML.</p>
<div id="fig-dashboard" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-dashboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="dashboard.png" class="img-fluid" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dashboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 6: An example wildfire prediction dashboard
</figcaption>
</figure>
</div>
</section>
<section id="challenges-1" class="level3">
<h3>Challenges</h3>
<ul>
<li>Major issues and solutions (dash-leaflet immutability)</li>
</ul>
</section>
<section id="availabilitysource-code-location" class="level3">
<h3>Availability/Source Code Location</h3>
<p>All of the source code can be found at <a href="https://github.com/nathanrethwisch/FinalProjectDS4010A">https://github.com/nathanrethwisch/FinalProjectDS4010A</a>. The dashboard is currently hosted at <a href="https://wildfire.ddole.net/">https://wildfire.ddole.net/</a>.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2>Conclusion</h2>
<section id="summary" class="level3">
<h3>Summary</h3>
<p>Using historical fire data from the United States Forest Service (USFS) and weather data from the National Oceanic and Atmospheric Administration (NOAA), we were able to create a random forest model and associated dashboard that predicted the probability of a fire occurring in a given area on a certain date. The dashboard allows users to explore dates and weather trends that lead to a high fire probability. This can be used for setting policy and garnering a greater understanding of the relationship between weather and wildfires.</p>
</section>
<section id="further-discussion" class="level3">
<h3>Further Discussion</h3>
<p>Given more time, we would aim to expand our analysis by incorporating additional datasets to enhance our predictive accuracy. We would include factors such as soil conditions and wind direction in specific areas as key predictors. Additionally, we would like to explore the probability of a fire occurring again in a region that has already had a recent wildfire. If we had access to greater computational resources, we would refine our predictions by using smaller hexagonal grids, allowing for more precise insights into distinct geographical climates. Moreover, the dashboard could be enhanced to support future fire prediction efforts. By using upcoming weather forecasts, we could provide a forecasted probability of fire occurrence in specific areas. These ideas lay the foundation for ongoing exploration and continued development of the dashboard.</p>
<p><strong>In the future, this data should be moved into cloud object storage.</strong></p>
</section>
<section id="sources" class="level3 unnumbered">
<h3 class="unnumbered">Sources</h3>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-jec2023wildfires" class="csl-entry" role="listitem">
U.S. Congress Joint Economic Committee. 2023. <span>“Climate-Exacerbated Wildfires Cost the u.s. Between $394 to $893 Billion Each Year in Economic Costs and Damages.”</span> <a href="https://www.jec.senate.gov/public/_cache/files/9220abde-7b60-4d05-ba0a-8cc20df44c7d/jec-report-on-total-costs-of-wildfires.pdf">https://www.jec.senate.gov/public/_cache/files/9220abde-7b60-4d05-ba0a-8cc20df44c7d/jec-report-on-total-costs-of-wildfires.pdf</a>.
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id = "quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->

</body>

</html>
